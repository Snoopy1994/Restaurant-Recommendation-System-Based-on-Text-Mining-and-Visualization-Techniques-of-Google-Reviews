{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ade8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a74c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import default module\n",
    "import os\n",
    "import time\n",
    "import math \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# import self module\n",
    "import utils\n",
    "import liwc_data\n",
    "import matplotlib.pyplot as plt\n",
    "import google_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a shorthand for loading a pickle file\n",
    "def read_pickle(path):\n",
    "    if path[-4:] != '.pkl':\n",
    "        raise ValueError\n",
    "        \n",
    "    with open(path, 'rb') as fd:\n",
    "        f = pickle.load(fd)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin_data = read_pickle(\"../../cleaned_data/tainan/1010 Hunan Cuisine.pkl\")\n",
    "# ws_data = read_pickle(\"../../cleaned_data/tainan/word_segments/1010 Hunan Cuisine.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = []\n",
    "# for words in ws_data['ws']:\n",
    "#     category = set()\n",
    "#     for word in words:\n",
    "#         if word not in four_aspect:\n",
    "#             continue\n",
    "#         category.update(four_aspect[word])\n",
    "#     categories.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = [\n",
    "    '../liwc_dictionary/LIWC2015.txt',\n",
    "    '../liwc_dictionary/new_add_liwc_dic.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e985e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dic = liwc_data.LingusticsInquiry()\n",
    "liwc_dic.add_dictionaries(*dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_scores(words, return_details=False):\n",
    "    \n",
    "    categories = [liwc_dic.get_categories(word) for word in words]\n",
    "    scores = np.r_[[get_score(category) for category in categories]]\n",
    "    \n",
    "    # assume a string containing space only is a delimiter of sentences\n",
    "    sentence_masks = np.r_[[len(word.strip()) == 0 for word in words]]\n",
    "    sentence_splits = np.where(sentence_masks)[0]\n",
    "    \n",
    "    key = 'negate (Negations)'\n",
    "    negate_masks = np.r_[[key in category for category in categories]]\n",
    "\n",
    "    # make both value is zero and is negate to -1\n",
    "    scores[(scores == 0) & negate_masks] = -1\n",
    "    \n",
    "    inpaint_score_masks = [\n",
    "        inpaint_scores(i) for i in np.split(scores, sentence_splits) if len(i) != 0]\n",
    "    inpaint_score_masks = np.hstack(inpaint_score_masks)\n",
    "    \n",
    "    labels = negate_masks | (scores != 0) | inpaint_score_masks\n",
    "    score_splits = utils.label_change(labels)\n",
    "    \n",
    "    splits = np.hstack([sentence_splits, score_splits])\n",
    "    splits = np.unique(splits)\n",
    "    \n",
    "    review_scores = [\n",
    "        get_segment_score(segment_scores)\n",
    "        for segment_scores in np.split(scores, splits)]\n",
    "    \n",
    "    if return_details:\n",
    "        arr = np.vstack([words, scores]).T\n",
    "        return review_scores, (arr, sentence_splits, splits)\n",
    "\n",
    "    return review_scores\n",
    "\n",
    "def get_review_score(words, return_details=False):\n",
    "    scores, details = get_review_scores(words, return_details=True)\n",
    "    score = np.sum(scores)\n",
    "    if return_details:\n",
    "        return score, details\n",
    "    return score\n",
    "\n",
    "def review_scores_based_on_sentence(words):\n",
    "    scores, (arr, sentence_splits, segment_splits) = \\\n",
    "        get_review_scores(words, return_details=True)\n",
    "    I = np.searchsorted(segment_splits, sentence_splits) + 1\n",
    "    sentence_scores = [np.sum(i) for i in np.split(scores, I)]\n",
    "    sentence_scores = [min(max(i, -1), 1) for i in sentence_scores]\n",
    "    return sentence_scores\n",
    "\n",
    "def score_to_star(numerator, denominator):\n",
    "    if numerator == 0:\n",
    "        return 2 * numerator + 3\n",
    "    return 2 * numerator / denominator + 3\n",
    "\n",
    "def get_score(categories):\n",
    "    # posemo (Positive Emotions) and negemo (Negative Emotions) can exist as the same time\n",
    "    _score_table = {\n",
    "        'posemo (Positive Emotions)': 1,\n",
    "        'negemo (Negative Emotions)': -1\n",
    "    }\n",
    "    \n",
    "    categories = set(categories)\n",
    "    scores = [_score_table.get(category, 0) for category in categories]\n",
    "    return 0 + sum(scores)\n",
    "\n",
    "# expand scores\n",
    "def inpaint_scores(nums):\n",
    "    # make [1, 0, 1] -> [?, True, ?]\n",
    "    return utils.sliding_mean(np.abs(nums), 1) > 0.6\n",
    "\n",
    "# scores, sentence splits, segment splits(including sentence splits)\n",
    "def get_segment_score(scores):\n",
    "    if np.all(scores == 0):\n",
    "        return 0\n",
    "    \n",
    "    scores[scores==0] = 1\n",
    "    return np.prod(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# senti_star = []\n",
    "# for n, (reviews, star) in enumerate(zip(ws_data[\"ws\"], ws_data['data'].stars)):\n",
    "#     scores = review_scores_based_on_sentence(reviews)\n",
    "#     numerator = np.sum(scores)\n",
    "#     denominator = len(np.nonzero(scores)[0])\n",
    "#     estimated_star = round(score_to_star(numerator, denominator), 2)\n",
    "#     senti_star.append(estimated_star)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = []\n",
    "# scores = [np.sum(review_scores_based_on_sentence(words)) for words in ws_data['ws']]\n",
    "# for score in scores:\n",
    "#     if score >= 1:\n",
    "#         category.append('postive')\n",
    "#     if score <= -1:\n",
    "#         category.append('negative')\n",
    "#     if score == 0:\n",
    "#         category.append('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pd.read_excel(\"../../dic.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = pd.read_excel(\"../../dic.xlsx\", sheet_name=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "four_aspect = {}\n",
    "\n",
    "for word, category in zip(dic['word'], dic['category']):\n",
    "    x = four_aspect.get(word, set())\n",
    "    x.add(category)\n",
    "    four_aspect[word] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# four_aspect = dic.set_index(['word'])[\"category\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df['time'] = origin_data.strftime()\n",
    "# df['star'] = origin_data.stars\n",
    "# df['username'] = origin_data.usernames\n",
    "# df['review'] = origin_data.reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['senti_star'] = np.nan\n",
    "# df['category'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0af4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['food'] = np.nan\n",
    "# df['service'] = np.nan\n",
    "# df['atmosphere'] = np.nan\n",
    "# df['value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13396868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = ws_data['data']\n",
    "# index = np.searchsorted(origin_data.index, a.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['senti_star'].loc[index] = senti_star\n",
    "# df['category'].loc[index] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['food'].loc[index] = [1 if 1 in i else np.nan for i in categories]\n",
    "# df['service'].loc[index] = [1 if 3 in i else np.nan for i in categories]\n",
    "# df['atmosphere'].loc[index] = [1 if 2 in i else np.nan for i in categories]\n",
    "# df['value'].loc[index] = [1 if 4 in i else np.nan for i in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b262bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path = '../../cleaned_data/taipei/'\n",
    "ws_path = '../../cleaned_data/taipei/word_segments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddf033",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.DataFrame()\n",
    "for filename in tqdm.tqdm(os.listdir(origin_path)):\n",
    "    if not filename.endswith('.pkl'):\n",
    "        continue\n",
    "    origin_data = read_pickle(os.path.join(origin_path, filename))\n",
    "    ws_data = read_pickle(os.path.join(ws_path, filename))\n",
    "    a = ws_data['data']\n",
    "    index = np.searchsorted(origin_data.index, a.index)\n",
    "    \n",
    "    senti_star = []\n",
    "    for n, (reviews, star) in enumerate(zip(ws_data[\"ws\"], ws_data['data'].stars)):\n",
    "        scores = review_scores_based_on_sentence(reviews)\n",
    "        numerator = np.sum(scores)\n",
    "        denominator = len(np.nonzero(scores)[0])\n",
    "        estimated_star = round(score_to_star(numerator, denominator), 2)\n",
    "        senti_star.append(estimated_star)   \n",
    "        \n",
    "    category = []\n",
    "    scores = [np.sum(review_scores_based_on_sentence(words)) for words in ws_data['ws']]\n",
    "    for score in scores:\n",
    "        if score >= 1:\n",
    "            category.append('positive')\n",
    "        if score <= -1:\n",
    "            category.append('negative')\n",
    "        if score == 0:\n",
    "            category.append('neutral')\n",
    "\n",
    "    categories = []\n",
    "    for words in ws_data['ws']:\n",
    "        cat = set()\n",
    "        for word in words:\n",
    "            if word not in four_aspect:\n",
    "                continue\n",
    "            cat.update(four_aspect[word])\n",
    "        categories.append(cat)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['time'] = origin_data.strftime()\n",
    "    df['star'] = origin_data.stars\n",
    "    df['username'] = origin_data.usernames\n",
    "    df['review'] = origin_data.reviews\n",
    "    df['senti_star'] = np.nan\n",
    "    df['category'] = 'no_review'\n",
    "    df['senti_star'][index] = senti_star\n",
    "    df['category'][index] = category\n",
    "    df['food'] = np.nan\n",
    "    df['service'] = np.nan\n",
    "    df['atmosphere'] = np.nan\n",
    "    df['value'] = np.nan\n",
    "    df['food'].loc[index] = [1 if 1 in i else np.nan for i in categories]\n",
    "    df['service'].loc[index] = [1 if 3 in i else np.nan for i in categories]\n",
    "    df['atmosphere'].loc[index] = [1 if 2 in i else np.nan for i in categories]\n",
    "    df['value'].loc[index] = [1 if 4 in i else np.nan for i in categories]\n",
    "    df['filename'] = filename.replace(\".pkl\", \"\")\n",
    "    total = total.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68657dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total[[\"filename\", \"time\", \"star\", \"username\", \"review\", 'senti_star', 'category', \n",
    "               'food', 'service', 'atmosphere', 'value']]\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02381e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total.to_csv(os.path.join('../../Google_review_code/result/review_with_sentiments/', \n",
    "#                           'taipei_review.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655d19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
